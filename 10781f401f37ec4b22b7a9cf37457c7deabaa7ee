{
  "comments": [
    {
      "key": {
        "uuid": "da1255d7_ec622316",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 39,
      "author": {
        "id": 6
      },
      "writtenOn": "2018-01-03T14:27:38Z",
      "side": 1,
      "message": "Just for my understanding: I understood that builds should be done in sequence for build dep requirements between rpm. So in which case we can run build in parallel ? or is there a mechanism in DLRN to check the build deps we can then use to decide if some package can be built in parallel ?",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_2b4945d1",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 39,
      "author": {
        "id": 200
      },
      "writtenOn": "2018-01-08T18:00:28Z",
      "side": 1,
      "message": "Right now, we could use two build modes:\n\n- sequential (the default when using the --order command-line switch) computes the right build order between dependent packages, and ensures they are built in the right order. Typically, this is only needed for the initial repo bootstrap.\n\n- parallel (the default mode, although we currently set up only 1 worker) does not ensure a 100% correct order when we run with more than 1 worker, but it\u0027s usually enough. The only corner case we could have is when two commits in two separate projects are merged at about the same time, and we really need one of them to depend on the other.",
      "parentUuid": "da1255d7_ec622316",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_8ca967e2",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 474
      },
      "writtenOn": "2018-01-02T09:41:54Z",
      "side": 1,
      "message": "Do we really need a communication protocol? Could we evaluate if we could rely only on the database as it would be much simler and robust?",
      "range": {
        "startLine": 51,
        "startChar": 1,
        "endLine": 53,
        "endChar": 7
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_0cbb3710",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 201
      },
      "writtenOn": "2018-01-02T13:35:40Z",
      "side": 1,
      "message": "Why ZMQ? IIUC it is removed as a dep in Zuul/Nodepool V3, so this would be adding new dep long term.",
      "range": {
        "startLine": 53,
        "startChar": 0,
        "endLine": 53,
        "endChar": 6
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_ac40ab08",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 166
      },
      "writtenOn": "2018-01-02T13:54:46Z",
      "side": 1,
      "message": "I\u0027m not found of using a database as an IPC. It\u0027s not suited to manage jobs queues.\n\nIf people worry about using ZMQ, we can switch to mere REST API but ZMQ provides reliable and flexible communication layer. Redis might be an alternative with pub/sub feature, too.",
      "parentUuid": "da1255d7_8ca967e2",
      "range": {
        "startLine": 51,
        "startChar": 1,
        "endLine": 53,
        "endChar": 7
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_4cf6cfd8",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 277
      },
      "writtenOn": "2018-01-02T17:39:12Z",
      "side": 1,
      "message": "I think the general idea is to have a queue of builds *somewhere* (even if that doesn\u0027t end up being zeromq) and then have workers pick up builds from that queue instead of the current architecture where each worker sequentially scans and builds packages.\n\nLet\u0027s not bikeshed on zeromq but instead agree whether or not this general direction makes sense.",
      "parentUuid": "da1255d7_0cbb3710",
      "range": {
        "startLine": 53,
        "startChar": 0,
        "endLine": 53,
        "endChar": 6
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_ecb903ee",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 201
      },
      "writtenOn": "2018-01-02T19:56:49Z",
      "side": 1,
      "message": "Agreed that ZeroMQ should not be explicitly mentioned in the spec.\n\nI wonder though if this is not reimplementing Zuul, could we consider https://github.com/openstack-infra/zuul/blob/feature/zuulv3/doc/source/admin/drivers/git.rst probably sub-classed  to take rdoinfo into account.",
      "parentUuid": "da1255d7_4cf6cfd8",
      "range": {
        "startLine": 53,
        "startChar": 0,
        "endLine": 53,
        "endChar": 6
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_6cdbd3ee",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 6
      },
      "writtenOn": "2018-01-03T14:27:38Z",
      "side": 1,
      "message": "I think avoiding dependencies from components that require system rights in order to be installed and managed (like zmq or mariadb) is better to keep DLRN easy to conf and run. Gearman is a protocol designed to be a task exchange (zuul mainly relies on it). A gearman server can be easily run in full python using the lib developed by openstack infra https://github.com/openstack-infra/gear/. http://gearman.org/\nRunning a gearman server (started by DLRN) could be completely transparent to the user for the single node use case.",
      "parentUuid": "da1255d7_4cf6cfd8",
      "range": {
        "startLine": 53,
        "startChar": 0,
        "endLine": 53,
        "endChar": 6
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_2c815b90",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 166
      },
      "writtenOn": "2018-01-03T15:53:16Z",
      "side": 1,
      "message": "Gearman requires a separate server, compared to a single C library + light wrapper (pyzmq).\n\nLet\u0027s assume that we want a communication layer and not assume technical choices at this stage.",
      "parentUuid": "da1255d7_6cdbd3ee",
      "range": {
        "startLine": 53,
        "startChar": 0,
        "endLine": 53,
        "endChar": 6
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_ec30e309",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 201
      },
      "writtenOn": "2018-01-03T17:38:15Z",
      "side": 1,
      "message": "Then proposal should be reworked to not mention explicit tech.choice.\nzmq even as inprocess is an infra we\u0027d need to debug and practical experience from openstack-infra is not positive hence it was abandoned.\nGearman is part of Zuul/SF so we\u0027d reuse it since DLRN is a part of SoftwareFactory.\nAt the same time, as already emphasized in the proposal, we\u0027d need to keep simple local case CLI, which works without any of the msg infra.",
      "parentUuid": "da1255d7_2c815b90",
      "range": {
        "startLine": 53,
        "startChar": 0,
        "endLine": 53,
        "endChar": 6
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_ab0bf57c",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 200
      },
      "writtenOn": "2018-01-08T18:00:28Z",
      "side": 1,
      "message": "I\u0027m replying globally, but this looks like the most important point to discuss so we can also arrange a session on it:\n\n- Using the DB as a synchronization layer could work, but we\u0027d need to add some locking stuff. I\u0027m not sure if SELECT ... FOR UPDATE works with SQLite3, would that work? If so, we could use a pending_commits table, and have each worker pick the first unbuilt commit.\n\n- About the reasons to choose ZeroMQ: it does not require any broker setup, so no additional infra (it\u0027s just a library). In fact, it could be any other library that allows us to set up message passing between different processes, regardless of the server they\u0027re running on (to handle the simple and complex use cases). I preferred to specify a library to provide a more concrete design, tbh, but we could change that.\n\n- About gearman: I\u0027ve had a look at https://github.com/openstack-infra/gear/, and it still looks a bit more complex than a ZeroMQ-based implementation. In the best case, using the geard python implementation could work, but it\u0027s labeled as \"not designed for production use under load\". If we use a standalone gearman, we\u0027d be in a similar situation to Rabbit or other broker.\n\n- About the Zuul reimplementation and Git driver: this is handled later on in the \"Alternatives\" section. Zuul is way more generic than what DLRN aims to be, and of course the simple use case is completely lost.",
      "parentUuid": "da1255d7_ec30e309",
      "range": {
        "startLine": 53,
        "startChar": 0,
        "endLine": 53,
        "endChar": 6
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_6e962b96",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 53,
      "author": {
        "id": 200
      },
      "writtenOn": "2018-01-09T12:10:35Z",
      "side": 1,
      "message": "I have been having a look at the chances of using a database for synchronization, and the results are not very promising:\n\n- With SQLite3, using SELECT ... FOR UPDATE does not actually lock any row, so we cannot easily use it to provide a new job atomically.\n\n- With MariaDB, it locks the rows, but there are some unwanted side effects, and it\u0027s very easy to create a deadlock. We could work with them using retries, see [1] for how oslo.db does it, but it looks overly complex to me compared to a message queuing library.\n\nAny hints, or should we discard this option?\n\n[1] - https://github.com/openstack/oslo.db/blob/master/oslo_db/api.py#L83",
      "parentUuid": "ba076199_ab0bf57c",
      "range": {
        "startLine": 53,
        "startChar": 0,
        "endLine": 53,
        "endChar": 6
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_0c00d7a9",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 74,
      "author": {
        "id": 277
      },
      "writtenOn": "2018-01-02T17:52:34Z",
      "side": 1,
      "message": "I\u0027m curious -- does this mean we would have on set of git repositories for all workers and releases ?\n\nRight now each worker clones and refreshes it\u0027s own copy of the repositories, right ?\n\nI can see it as a good thing since it means less resource utilization (both cpu and disk space) but it might break some assumptions (i.e, checking out specific commits/branches)",
      "range": {
        "startLine": 74,
        "startChar": 34,
        "endLine": 74,
        "endChar": 62
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_2b770504",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 74,
      "author": {
        "id": 200
      },
      "writtenOn": "2018-01-08T18:00:28Z",
      "side": 1,
      "message": "That\u0027s a good point, I hadn\u0027t thought of that. My idea was that each worker would be specific to one scheduler, so it would not build Pike _and_ Ocata packages, for example.\n\nOne alternative would be to make this scheduler work with multiple different releases, and then each worker could build packages for any of them... but I think this would make it more complex than it is already.",
      "parentUuid": "da1255d7_0c00d7a9",
      "range": {
        "startLine": 74,
        "startChar": 34,
        "endLine": 74,
        "endChar": 62
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_ccf2bf6f",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 79,
      "author": {
        "id": 6
      },
      "writtenOn": "2018-01-03T14:27:38Z",
      "side": 1,
      "message": "In case wokers are not in the same node than the scheduler, workers will access scheduler repositories via git+ssh ?",
      "range": {
        "startLine": 77,
        "startChar": 0,
        "endLine": 79,
        "endChar": 22
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_0b7441fb",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 79,
      "author": {
        "id": 200
      },
      "writtenOn": "2018-01-08T18:00:28Z",
      "side": 1,
      "message": "I had not thought of this. My initial thought is that it should get the repos itself, although it would defeat some use cases (--dev and --local).\n\nWe need to consider if we want to add the setup complexity of allowing access via git+ssh to the scheduler, or reduce the scope of supported options for the complex use case.",
      "parentUuid": "da1255d7_ccf2bf6f",
      "range": {
        "startLine": 77,
        "startChar": 0,
        "endLine": 79,
        "endChar": 22
      },
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_8c7167e3",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 93,
      "author": {
        "id": 6
      },
      "writtenOn": "2018-01-03T14:27:38Z",
      "side": 1,
      "message": "As mentioned by Alan there is now a Git driver in Zuul. I think it worth to think a bit about how to run DLRN on top of zuul in order to adjust some pieces of DLRN during this spec implementation like maybe adding ansible roles to build packages, to export build to the repo manager (so consumable by zuul) and use them in DLRN if possible. wdyt ?",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_8b5ef174",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 93,
      "author": {
        "id": 200
      },
      "writtenOn": "2018-01-08T18:00:28Z",
      "side": 1,
      "message": "My biggest fear for this kind of setup is scale. With the Git driver for Zuulv3, we could do something like:\n\n- Create a post job for all distgit repos, that builds the package on every merged commit.\n- Create a configuration for all source repos, using the Git driver. Then, for all repos supported by rdoinfo, add the same post job to build the package.\n\nThat job could easily export the build using the DLRN API (all the code bits are there, and we\u0027d just need to use a credential for the API).\n\nWe would need to set up a fair amount of automation to make sure each new project gets built... It\u0027s doable, and the Git driver makes it feasible once it\u0027s in review.rdoproject.org. However, I still think that the scale is quite big.",
      "parentUuid": "da1255d7_8c7167e3",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_cb998921",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 93,
      "author": {
        "id": 201
      },
      "writtenOn": "2018-01-08T21:37:49Z",
      "side": 1,
      "message": "Is your concern scale of adding Zuul job definitions or Zuul handling them?",
      "parentUuid": "ba076199_8b5ef174",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_8e803f48",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 93,
      "author": {
        "id": 200
      },
      "writtenOn": "2018-01-09T12:10:35Z",
      "side": 1,
      "message": "It\u0027s not about Zuul\u0027s ability to handle them, it\u0027s about overall operational cost. We\u0027d have to define automation to create the Zuul job definitions, but also debugging issues would become way more complex.\n\nFor example, if a package was not built for whatever reason we\u0027d have to find its post job log (if it\u0027s there) to find out what happened and why. If it\u0027s not there, we need to figure out why that job did not run, and then we need to have permissions to access the Zuul logs...\n\nWith the current DLRN structure, it\u0027s all contained in the worker user directory, if we use Zuul we\u0027re making it increasingly complex by adding multiple sources of information (rdoinfo, the Zuul definitions, etc) and places to debug.",
      "parentUuid": "ba076199_cb998921",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_0cc5775a",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 105,
      "author": {
        "id": 201
      },
      "writtenOn": "2018-01-03T17:38:15Z",
      "side": 1,
      "message": "ZMQ is only available for \"free\" while SoftwareFactory keeps ZuulV2, long-term it will be gone.",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_eb5fad73",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 105,
      "author": {
        "id": 200
      },
      "writtenOn": "2018-01-08T18:00:28Z",
      "side": 1,
      "message": "Not really, it does not require a broker. You can have a look at [1] for some simple examples of how to use the library in Python.\n\n[1] - https://www.digitalocean.com/community/tutorials/how-to-work-with-the-zeromq-messaging-library",
      "parentUuid": "da1255d7_0cc5775a",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ba076199_0bf9e14d",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 105,
      "author": {
        "id": 201
      },
      "writtenOn": "2018-01-08T21:35:07Z",
      "side": 1,
      "message": "My concern was more operational overhead, even in-process it\u0027s infrastructure which needs to be monitored and troubleshooted, experience from upstream openstack-infra was not that good.",
      "parentUuid": "ba076199_eb5fad73",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da1255d7_0c7e97ae",
        "filename": "doc/specs/new-architecture-sched-worker.rst",
        "patchSetId": 2
      },
      "lineNbr": 180,
      "author": {
        "id": 166
      },
      "writtenOn": "2018-01-03T15:53:16Z",
      "side": 1,
      "message": "Plan make sense.",
      "revId": "10781f401f37ec4b22b7a9cf37457c7deabaa7ee",
      "serverId": "6c1dc8ef-8b94-40e4-bd83-c2359d45ecc0",
      "unresolved": false
    }
  ]
}